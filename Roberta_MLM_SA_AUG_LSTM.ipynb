{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1653195651415,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"},"user_tz":-420},"id":"UJGL0qzsah8u","outputId":"95c1ffc5-1396-4f81-c36f-b651e5ae8595"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun May 22 05:00:50 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"qy1rG8X53sPF","executionInfo":{"status":"ok","timestamp":1653195652976,"user_tz":-420,"elapsed":655,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15520,"status":"ok","timestamp":1653195668489,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"},"user_tz":-420},"id":"EtEk6V7iOfhd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eec9b822-9abb-47f0-c880-9480a717b092"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 4.2 MB 4.3 MB/s \n","\u001b[K     |████████████████████████████████| 84 kB 3.7 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 24.0 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 58.6 MB/s \n","\u001b[K     |████████████████████████████████| 346 kB 4.3 MB/s \n","\u001b[K     |████████████████████████████████| 212 kB 75.0 MB/s \n","\u001b[K     |████████████████████████████████| 140 kB 70.2 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 62.1 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 75.8 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 71.0 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 4.4 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 77.7 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q transformers\n","!pip install -q datasets"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5915,"status":"ok","timestamp":1653195674397,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"},"user_tz":-420},"id":"zar7AVFcOzfS"},"outputs":[],"source":["#transformers\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import RandomOverSampler \n","import pandas as pd\n","import numpy as np\n","import torch\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","from transformers import Trainer, TrainingArguments"]},{"cell_type":"code","source":["tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"],"metadata":{"id":"SoFp7KcAh1aX","executionInfo":{"status":"ok","timestamp":1653195683668,"user_tz":-420,"elapsed":9280,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["8bfe5f5455124ba293da489f372b364e","f0a8d8e253204a9ca3b080dd58b56897","eb10f905bc0a402c9009d248c65912a0","55c50fda40384b40831a7e51aa09b9ef","8d7da57c140e4263a05a9cbaa6a2f732","53d85775b56e45b6bdf250ccd48b6b8b","1f41673a4800441ba0c1f962b823b77c","83a8fa136d8e4f3394b071c115cea31b","b9cf8e1fa3cf4952befd2412bd0a0481","091bff1ac7c54eea9fc0aff38f13062d","e50b2a08f58d463593c401ba1a853446","4f1d4849d52b4800be0f5a77573e0269","b9cb9e7708384d14ae670cb0fe7a9c43","f0cec2da338445ec90bc9fbfb375d3b3","4e60751145f84b0780f6c9efe045033b","43263f467ae04bb8b0c14cd3a458a10f","b48c696108a24ed297a84641c21795fa","1c5dd3aaa9014c5d8f1ca4a0cb86df57","ca42bad3ddf942cca6912ab2c00356d6","5c3795a5c65442b78dc00a612adef816","076f4544298046a188f0df2b53b80891","aef753d83eef48f0b73b210ba25c7c1c","a3c373fc256a4bf4b6dc8bb45ac9c5e7","7a43672ffcfd4ceaad8672f11e416d53","3d079373fd9d48c294ba1cc24a94123e","1230bcd2d0c7430a8930c1c8dc86ded6","30765293fe4f4253840765e5988508dd","74b38ee6396a4479996201e0fbd26f91","650dc7db920c47cc84deeab5fc5813a5","24e5773a3e314154942f963bf55ac0ad","e0a0b2f09de44e15b3b7ac4e731ddfe5","7bc5ef78a544484ca8e72727e84c914d","fe8c393bd7c240cfaecba0d0f54e417d"]},"outputId":"e10d50e8-bd4e-4345-e3ed-f8cf7ca821b5"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bfe5f5455124ba293da489f372b364e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f1d4849d52b4800be0f5a77573e0269"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3c373fc256a4bf4b6dc8bb45ac9c5e7"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"ciWQXgp0SAD3"},"source":["# Load Dataset\n"]},{"cell_type":"code","source":["train_dataset_path = \"/content/drive/MyDrive/NLP/Setiment_Analysis/en/dataset/covid-19/aug_clean_train.csv\"\n","test_dataset_path = \"/content/drive/MyDrive/NLP/Setiment_Analysis/en/dataset/covid-19/clean_test.csv\""],"metadata":{"id":"RhWshjVggda9","executionInfo":{"status":"ok","timestamp":1653195683668,"user_tz":-420,"elapsed":3,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset, load_dataset\n","\n","dataset = load_dataset('csv', data_files={'train': train_dataset_path,\n","                                          'val': test_dataset_path})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185,"referenced_widgets":["6b8187b8be89420a8d9e915c781b6e01","dfd469b88ab744dcaec6c936ac67c628","b8783f42996f4e3099f86e7ad3d1dff5","f4d4ca3d6c4f48c9a17e68df5dafd400","038c27c392fd462c9ac1cb17c143ea91","8616bdd6d8ab4a32a11f0b124cb669b1","3307bcecd950446d86f8971cc7f1b474","56413c54867445babffacd4fd9f86b30","792857cfc1504883adc806f4f564c6a5","032c823fe70e4bb697487258a231daee","ccfcd5cf8a1e47f09b2b1437887b78f4","f5a1808efef940f68941689cbef8b61c","c80e5183e8d54c078771c12581680d4e","cdb381a4eb774471bcfcffa6a27dba75","2343bef247a64e52ad3c06824c79e4bd","8e3097ec32cb48eeb62638dbe57f417a","59d6e59d39b742dfbbb9bdd98c5ee12c","da1d62701c354500acec104851a5e2da","0741c9e622c84959a894cf92e376c335","f9f81ea69cf8464d9b8faf9af2521bf4","bf8f70c83b864c559348ce8b2b26ac11","6cdfed30cfbf4b799d6ea6c896c27820","b2b315c15c4e4c5ba3be7e45cb2e7aa3","45155038522c489aa442ad3ca6e4aece","e164af8df49740d7bcb0c303f098eade","96374ec1ad71469094e50029291c3778","d0b70dc24991452ead8a0d6817fc6086","35c0352794624c9595fe5f5456067d78","54d0d38bdda4400291c19ebf97ca7545","9968c5be25e94cc7b70e1cde3e242063","b3167a4583c84a919eb2dacf5686bb68","3b42520602b04437b20a8ed7db6fb52c","12a3cdb608444a61a388417ad2ca0364"]},"id":"pWE5R3ylesdm","executionInfo":{"status":"ok","timestamp":1653195688454,"user_tz":-420,"elapsed":4788,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}},"outputId":"a1c80825-41d7-4f76-b58e-06f9956bc66e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Using custom data configuration default-c23d9ec77aab9cc0\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-c23d9ec77aab9cc0/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b8187b8be89420a8d9e915c781b6e01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5a1808efef940f68941689cbef8b61c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-c23d9ec77aab9cc0/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2b315c15c4e4c5ba3be7e45cb2e7aa3"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Preprocess data"],"metadata":{"id":"9sgbjZx9o6G2"}},{"cell_type":"code","source":["dataset = dataset.rename_column(\"text_clean\", \"texts\")\n","dataset = dataset.rename_column(\"Sentiment\", \"labels\")\n","# dataset['train'], dataset['validation'] = dataset['train'].train_test_split(0.2).values()"],"metadata":{"id":"t5htSYiRjY8l","executionInfo":{"status":"ok","timestamp":1653195688455,"user_tz":-420,"elapsed":20,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def label_mapping(examples):\n","    label_to_idx = {'Extremely Negative': 0, 'Negative': 0, 'Neutral': 1,\n","                    'Positive': 2, 'Extremely Positive': 2}\n","    examples[\"labels\"] = label_to_idx[examples[\"labels\"]]\n","    return examples\n","    \n","dataset = dataset.map(label_mapping)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["02af12f86808471b9150ad42cae9804b","567ffa86e77547d1904e7f5beea53df5","032e6139d41f4fe0b8148f06f044ee06","88b61bde4c5e4bb48479e822c90874f2","fd506beb6b394c9daa5be29de3de3af1","91d770ee6fcb4d388e5dfa0cec6cb774","1d830139b1f345aa8dd6aa4153e77279","d9dd0ce841af481d96ad1203bf0e93c4","e82b0c38408d4335a0fca1b0dccec435","22706a62b9364d01bf7c764aca294ebf","ab76ae10b2bb41a59fb525d292aee98f","cd696601313a477ba2c93d19f6134f73","9bc5856a783d40cb87b3a5839034aa9e","2ce2e818d7444127b2996cd191edf34f","ed9e498806ec46ebb74ee37f72d65ae8","3ae845b1e2e1471cb89e5ad0463e1b55","709cf7a56f3348e894dd322c6fffb6c9","700addea38a34ce8b0ea5ce4af900067","2fb68d70471b4d59893cc240f185004a","7f58bc6605664f7bae3923479cabc1f2","8a7818805116496da60a86a5dd5a4bc0","fbc100ee3d58460dae843384000ce883"]},"id":"MT_CQVthj75v","executionInfo":{"status":"ok","timestamp":1653195691902,"user_tz":-420,"elapsed":3465,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}},"outputId":"d2d56435-209f-43a0-c2f7-c15259d71a70"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/48483 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02af12f86808471b9150ad42cae9804b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3787 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd696601313a477ba2c93d19f6134f73"}},"metadata":{}}]},{"cell_type":"code","source":["def tokenizer_function(examples):\n","    result = tokenizer(examples[\"texts\"], max_length=128,\n","                       padding='max_length', truncation=True)\n","    result[\"labels\"] = examples[\"labels\"]\n","    return result\n","\n","tokenized_datasets = dataset.map(tokenizer_function, batched=True, remove_columns=['texts', 'labels'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["460e860ed15c44a59f7885c19f559f48","a3891ada27584f85918d051dd8ca786b","b257631d46e240fd972331a0edde4198","5131595b56f64ce093f435aec7d24ec2","16f8a3580d4947a1afe8a69abbba5363","b01130a2d73f47d6addead9be14f7925","44417b36175a40cebf178be2b203c5dd","bd4d01df02884d21a89a7d4d5da2e808","2ebcbd7b7a3f4b778b052dc786ed3fe7","9841ed5236634365a0060270aa7235d2","032a30131aaf458fa162b1fc3130f2a2","a14b6787f819406f9408463345b00624","2fbaf0d41a7a40788aebe81a3096cf6b","9aea277dc0b248648a3f5e04237af5a8","afe6844a6cdc46eca0041e5908cb358e","0ac7ae015fb2420792aac2c507ead171","4c2de58f3add41e0a6a9c721c60f9176","04af3918820743b5981b27c3d53dd29b","350ac5c5238243ae967238256cffa842","4dfe1f11fc5b4b5abace25a0252b0a6e","f7176825f0984128babae6d5f93787ca","f0bbef3c525a4486bdd8ca0dc24f8eef"]},"id":"QOUWCqyPfVd7","executionInfo":{"status":"ok","timestamp":1653195711597,"user_tz":-420,"elapsed":19731,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}},"outputId":"964dfd86-3662-4781-9a03-b8ec5c02fa71"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/49 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"460e860ed15c44a59f7885c19f559f48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a14b6787f819406f9408463345b00624"}},"metadata":{}}]},{"cell_type":"code","source":["tokenized_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b5R8U-jhkpq_","executionInfo":{"status":"ok","timestamp":1653195711598,"user_tz":-420,"elapsed":15,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}},"outputId":"7fed78af-7ac7-43aa-a282-b9619ad6982f"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['labels', 'input_ids', 'attention_mask'],\n","        num_rows: 48483\n","    })\n","    val: Dataset({\n","        features: ['labels', 'input_ids', 'attention_mask'],\n","        num_rows: 3787\n","    })\n","})"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["# Roberta + LSTM"],"metadata":{"id":"cgLHpkwI9Rr8"}},{"cell_type":"code","source":["import torch \n","from transformers import RobertaModel\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","\n","class CustomModel(torch.nn.Module):\n","    def __init__(self, checkpoint, num_labels):\n","        super(CustomModel, self).__init__()\n","        self.num_labels = num_labels\n","        self.criterion = torch.nn.CrossEntropyLoss()\n","\n","        # Load model with given checkpoint and extract its body\n","        self.model = RobertaModel.from_pretrained(checkpoint, num_labels=self.num_labels)\n","        self.dropout = torch.nn.Dropout(0.1)\n","        self.lstm = torch.nn.LSTM(768, 256, batch_first=True, bidirectional=True)\n","        self.classifier = torch.nn.Linear(256*2, self.num_labels)\n","    \n","    def forward(self, input_ids, attention_mask, labels=None):\n","        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n","        sequence_output = self.dropout(outputs[0])\n","\n","        lstm_output, (h, c) = self.lstm(sequence_output)\n","        hidden = torch.cat((lstm_output[:, -1, :256], lstm_output[:, 0, :256]), dim=-1)\n","        logits = self.classifier(hidden.view(-1, 256*2))\n","\n","        loss = None\n","        if labels is not None:\n","            loss = self.criterion(logits.view(-1, self.num_labels), labels.view(-1))\n","        \n","        return SequenceClassifierOutput(loss=loss, logits=logits,\n","                                        hidden_states=outputs.hidden_states,\n","                                        attentions=outputs.attentions)"],"metadata":{"id":"tEbNWhcB9WRL","executionInfo":{"status":"ok","timestamp":1653195711598,"user_tz":-420,"elapsed":11,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# model = CustomModel(\"/content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2\", num_labels=3)"],"metadata":{"id":"wD_hBViXCvuO","executionInfo":{"status":"ok","timestamp":1653195711598,"user_tz":-420,"elapsed":11,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Fine-tuning Roberta with Trainer API"],"metadata":{"id":"HU-3fh7Yozru"}},{"cell_type":"code","source":["from datasets import load_metric\n","\n","def compute_metrics(eval_preds):\n","    accuracy_metric = load_metric(\"accuracy\")\n","    precision_metric = load_metric(\"precision\")\n","    recall_metric = load_metric(\"recall\")\n","    f1_metric = load_metric(\"f1\")\n","\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n","    precision = precision_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n","    recall = recall_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n","    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n","\n","    return {\n","        \"accuracy\": accuracy['accuracy'],\n","        \"precision\": precision['precision'],\n","        \"recall\": recall['recall'],\n","        \"f1\": f1['f1'],\n","    }"],"metadata":{"id":"KybYJfNTTh9l","executionInfo":{"status":"ok","timestamp":1653195711598,"user_tz":-420,"elapsed":10,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    \"/content/output\",\n","    num_train_epochs=10,\n","    evaluation_strategy='epoch',\n","    load_best_model_at_end=True,\n","    metric_for_best_model = 'f1',\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=128,\n","    per_device_eval_batch_size=128,\n","    save_strategy = \"epoch\",\n","    logging_steps=200\n",")"],"metadata":{"id":"lCa72JXPsslk","executionInfo":{"status":"ok","timestamp":1653195712236,"user_tz":-420,"elapsed":16,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# trainer=Trainer(\n","#     model=model,\n","#     args=training_args,\n","#     train_dataset=tokenized_datasets['train'],\n","#     eval_dataset=tokenized_datasets['val'],\n","#     compute_metrics=compute_metrics,\n","# )"],"metadata":{"id":"RCiLJRt1t7_h","executionInfo":{"status":"ok","timestamp":1653195712237,"user_tz":-420,"elapsed":16,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# trainer.train()"],"metadata":{"id":"wGO-h-hYx4xT","executionInfo":{"status":"ok","timestamp":1653195712239,"user_tz":-420,"elapsed":17,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["# Hyperparameter search"],"metadata":{"id":"znKanSypYh1i"}},{"cell_type":"code","source":["! pip install -q optuna\n","! pip install -q ray[tune]"],"metadata":{"id":"WY0oS7prYknW","executionInfo":{"status":"ok","timestamp":1653195730636,"user_tz":-420,"elapsed":18413,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"30257851-a679-4c33-953d-170add5fe92b"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |█                               | 10 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 3.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 184 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 235 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 256 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 276 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 296 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 308 kB 3.8 MB/s \n","\u001b[K     |████████████████████████████████| 210 kB 92.7 MB/s \n","\u001b[K     |████████████████████████████████| 81 kB 11.1 MB/s \n","\u001b[K     |████████████████████████████████| 78 kB 8.6 MB/s \n","\u001b[K     |████████████████████████████████| 49 kB 7.0 MB/s \n","\u001b[K     |████████████████████████████████| 146 kB 90.6 MB/s \n","\u001b[K     |████████████████████████████████| 112 kB 90.6 MB/s \n","\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 53.2 MB 98.2 MB/s \n","\u001b[K     |████████████████████████████████| 4.1 MB 66.0 MB/s \n","\u001b[K     |████████████████████████████████| 8.8 MB 68.6 MB/s \n","\u001b[K     |████████████████████████████████| 125 kB 95.5 MB/s \n","\u001b[K     |████████████████████████████████| 461 kB 50.0 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["def model_init():\n","    return CustomModel(\"/content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2\", num_labels=3)"],"metadata":{"id":"AthGnbNBYoQY","executionInfo":{"status":"ok","timestamp":1653195730636,"user_tz":-420,"elapsed":29,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["from transformers import EarlyStoppingCallback\n","\n","trainer=Trainer(\n","    model_init=model_init,\n","    args=training_args,\n","    train_dataset=tokenized_datasets['train'],\n","    eval_dataset=tokenized_datasets['val'],\n","    compute_metrics=compute_metrics,\n","    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wy7in7G6Ys5L","executionInfo":{"status":"ok","timestamp":1653195753506,"user_tz":-420,"elapsed":22897,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}},"outputId":"78c49d2d-76d4-492c-daa1-aea9ee690ae2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["def my_hp_space(trial):\n","    return {\n","        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-6, 5e-5, log=True),\n","        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n","    }\n","\n","best_run = trainer.hyperparameter_search(n_trials=15, direction=\"maximize\", hp_space=my_hp_space)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d6988625fa4143bcb7ffc326d114b400","e38893acdca74adb9428c6bca00a55cd","c5259c1e1e644788918a6aabc21e91cc","208ea26534f94cecaf23e1d46d95c9ed","ac63c51c73fc4489a13e06414684a7b2","eccd79dae01a45fb8043fd2731e6ce6b","b85bd6fd102944559b8ed97b97e41d51","a421740aaa254becb4ecc79b9e5a2722","ebab5378de424e07a18e755b78734c51","9f9973f4d878444c89feb54bed3c3b64","1ac507570a5043a1afe82d3b25bbf440","4bb17205d3964fcebdeb4bb07d764b1a","40fe2d6577474dc0abfb953ccf65d313","8a6164522f1b4864b5b4c0130b8852f2","3075d2e71e6b4152810c6a9504a5b24b","e2ab839c40d0485682eaa2d65d7cb979","70148f1330f9473487dab281dec80fdb","f1ad950d3f92453088a033e8509e2d72","8fc408e5f2e141f69c8ae835f85ed9a7","6b43ad3ca67b43afa0a7f0d27477464e","5afd6f197e4142e3bb8dd2102601fd5b","4de7ff5eca884345b45eb1f86b45958e","1f2f2b1790ec4c609a343ddd86bba245","8771f51d5ee94b729e2dda3cf60580cf","644ad60936754a67849329a6533061b1","498d852f11404519b6b5b31311aec4ad","04ccffbdfbab4b04b9f6c6ef3e17434d","037ef7b1af3c47a69e157ffe0da9b3ea","105187ade65e4861b9243895edbfd83b","048ab5db3e384afc9474477b6a02e87e","48fd4ba86ade4b228234626d09982f81","696eb6f08be947e2a5d90966d0ccff64","a4f54c3c5d3f42bda034899d93eaa1f1","be5202ce3f1a47a1a493f52a07460993","de702a633b8145108310729419fbdde4","5a0f67bb19b0407da0d87a45472570a9","7ece19f024074212a6427c78ea1c848c","d63e171c687246f49a1e02e1fa8e66b2","51e1959c5fd54734beca7252179a4779","ed71bb5f209d4115a5cfb3f93e293385","7aa6737babde43da8232287f9ce04b2f","5a73a1fd33f341e9854b4d352cb65ca3","0406f433f14946459d9633041c0aa4c8","69401b008f0f425db66ae7a75e118808"]},"id":"PQmujFMeYxTf","outputId":"86f48663-c5ac-4729-db39-30eaae74d8db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2022-05-22 05:02:33,246]\u001b[0m A new study created in memory with name: no-name-7270963a-6258-47b1-b59b-479a02e6525c\u001b[0m\n","Trial:\n","loading configuration file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 48483\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3790\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2653' max='3790' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2653/3790 1:04:24 < 27:37, 0.69 it/s, Epoch 7/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.642200</td>\n","      <td>0.403634</td>\n","      <td>0.857671</td>\n","      <td>0.863355</td>\n","      <td>0.829837</td>\n","      <td>0.843280</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.320700</td>\n","      <td>0.329338</td>\n","      <td>0.895432</td>\n","      <td>0.893975</td>\n","      <td>0.874522</td>\n","      <td>0.883280</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.227800</td>\n","      <td>0.331436</td>\n","      <td>0.894640</td>\n","      <td>0.891007</td>\n","      <td>0.875002</td>\n","      <td>0.882307</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.169300</td>\n","      <td>0.341672</td>\n","      <td>0.897544</td>\n","      <td>0.904487</td>\n","      <td>0.872179</td>\n","      <td>0.885854</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.126400</td>\n","      <td>0.376485</td>\n","      <td>0.897280</td>\n","      <td>0.888229</td>\n","      <td>0.879980</td>\n","      <td>0.883916</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.095400</td>\n","      <td>0.395021</td>\n","      <td>0.886454</td>\n","      <td>0.862385</td>\n","      <td>0.872019</td>\n","      <td>0.866851</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.070000</td>\n","      <td>0.480591</td>\n","      <td>0.885926</td>\n","      <td>0.871558</td>\n","      <td>0.867156</td>\n","      <td>0.868775</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6988625fa4143bcb7ffc326d114b400"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.58k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bb17205d3964fcebdeb4bb07d764b1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.52k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f2f2b1790ec4c609a343ddd86bba245"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be5202ce3f1a47a1a493f52a07460993"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/output/run-0/checkpoint-379\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-0/checkpoint-758\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-0/checkpoint-1137\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-0/checkpoint-1516\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-0/checkpoint-1895\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-0/checkpoint-2274\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-0/checkpoint-2653\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/output/run-0/checkpoint-1516 (score: 0.8858535519329876).\n","\u001b[32m[I 2022-05-22 06:07:01,131]\u001b[0m Trial 0 finished with value: 3.4934152832724523 and parameters: {'learning_rate': 4.759285426103993e-05, 'num_train_epochs': 10}. Best is trial 0 with value: 3.4934152832724523.\u001b[0m\n","Trial:\n","loading configuration file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 48483\n","  Num Epochs = 9\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3411\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3411' max='3411' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3411/3411 1:22:48, Epoch 9/9]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.761200</td>\n","      <td>0.478727</td>\n","      <td>0.813309</td>\n","      <td>0.802071</td>\n","      <td>0.790150</td>\n","      <td>0.794885</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.411700</td>\n","      <td>0.385315</td>\n","      <td>0.866385</td>\n","      <td>0.864585</td>\n","      <td>0.840039</td>\n","      <td>0.850689</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.315200</td>\n","      <td>0.372695</td>\n","      <td>0.870610</td>\n","      <td>0.870878</td>\n","      <td>0.844520</td>\n","      <td>0.855772</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.258900</td>\n","      <td>0.346979</td>\n","      <td>0.877476</td>\n","      <td>0.870757</td>\n","      <td>0.858680</td>\n","      <td>0.863988</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.213700</td>\n","      <td>0.348744</td>\n","      <td>0.883285</td>\n","      <td>0.882254</td>\n","      <td>0.855119</td>\n","      <td>0.866627</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.185000</td>\n","      <td>0.358173</td>\n","      <td>0.883285</td>\n","      <td>0.877719</td>\n","      <td>0.859257</td>\n","      <td>0.867270</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.161900</td>\n","      <td>0.378874</td>\n","      <td>0.884869</td>\n","      <td>0.876787</td>\n","      <td>0.859527</td>\n","      <td>0.867314</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.144700</td>\n","      <td>0.405101</td>\n","      <td>0.878004</td>\n","      <td>0.868447</td>\n","      <td>0.849753</td>\n","      <td>0.858070</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.135200</td>\n","      <td>0.409288</td>\n","      <td>0.881701</td>\n","      <td>0.869846</td>\n","      <td>0.857015</td>\n","      <td>0.862939</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-1/checkpoint-379\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-1/checkpoint-758\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-1/checkpoint-1137\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-1/checkpoint-1516\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-1/checkpoint-1895\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-1/checkpoint-2274\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-1/checkpoint-2653\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-1/checkpoint-3032\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-1/checkpoint-3411\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/output/run-1/checkpoint-2653 (score: 0.867313815244854).\n","\u001b[32m[I 2022-05-22 07:29:52,725]\u001b[0m Trial 1 finished with value: 3.4715006720236117 and parameters: {'learning_rate': 1.5759995462622194e-05, 'num_train_epochs': 9}. Best is trial 0 with value: 3.4934152832724523.\u001b[0m\n","Trial:\n","loading configuration file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 48483\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3032\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3032' max='3032' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3032/3032 1:13:42, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.777200</td>\n","      <td>0.493595</td>\n","      <td>0.803274</td>\n","      <td>0.793727</td>\n","      <td>0.777391</td>\n","      <td>0.783815</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.429100</td>\n","      <td>0.399169</td>\n","      <td>0.852126</td>\n","      <td>0.852699</td>\n","      <td>0.823420</td>\n","      <td>0.835640</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.331800</td>\n","      <td>0.381201</td>\n","      <td>0.866913</td>\n","      <td>0.864846</td>\n","      <td>0.843640</td>\n","      <td>0.852964</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.276900</td>\n","      <td>0.355429</td>\n","      <td>0.872194</td>\n","      <td>0.865664</td>\n","      <td>0.853663</td>\n","      <td>0.859120</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.235800</td>\n","      <td>0.355862</td>\n","      <td>0.879588</td>\n","      <td>0.876630</td>\n","      <td>0.855412</td>\n","      <td>0.864771</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.207900</td>\n","      <td>0.360206</td>\n","      <td>0.880116</td>\n","      <td>0.873613</td>\n","      <td>0.854299</td>\n","      <td>0.862781</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.187100</td>\n","      <td>0.380697</td>\n","      <td>0.880380</td>\n","      <td>0.877698</td>\n","      <td>0.853647</td>\n","      <td>0.864117</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.172500</td>\n","      <td>0.390667</td>\n","      <td>0.881965</td>\n","      <td>0.876550</td>\n","      <td>0.855585</td>\n","      <td>0.864851</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-2/checkpoint-379\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-2/checkpoint-758\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-2/checkpoint-1137\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-2/checkpoint-1516\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-2/checkpoint-1895\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-2/checkpoint-2274\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-2/checkpoint-2653\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-2/checkpoint-3032\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/output/run-2/checkpoint-3032 (score: 0.8648509119891822).\n","\u001b[32m[I 2022-05-22 08:43:38,232]\u001b[0m Trial 2 finished with value: 3.4789506193311346 and parameters: {'learning_rate': 1.4106371520587412e-05, 'num_train_epochs': 8}. Best is trial 0 with value: 3.4934152832724523.\u001b[0m\n","Trial:\n","loading configuration file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 48483\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2653\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2274' max='2653' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2274/2653 55:12 < 09:12, 0.69 it/s, Epoch 6/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.681300</td>\n","      <td>0.408960</td>\n","      <td>0.856351</td>\n","      <td>0.854071</td>\n","      <td>0.835602</td>\n","      <td>0.843552</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.352000</td>\n","      <td>0.355524</td>\n","      <td>0.878268</td>\n","      <td>0.876562</td>\n","      <td>0.855291</td>\n","      <td>0.864651</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.262600</td>\n","      <td>0.360864</td>\n","      <td>0.885661</td>\n","      <td>0.882763</td>\n","      <td>0.864415</td>\n","      <td>0.872485</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.204000</td>\n","      <td>0.345763</td>\n","      <td>0.885661</td>\n","      <td>0.888348</td>\n","      <td>0.861245</td>\n","      <td>0.872432</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.159600</td>\n","      <td>0.361395</td>\n","      <td>0.884869</td>\n","      <td>0.874244</td>\n","      <td>0.859403</td>\n","      <td>0.866178</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.130800</td>\n","      <td>0.372009</td>\n","      <td>0.890151</td>\n","      <td>0.874311</td>\n","      <td>0.870069</td>\n","      <td>0.872132</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-3/checkpoint-379\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-3/checkpoint-758\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-3/checkpoint-1137\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-3/checkpoint-1516\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-3/checkpoint-1895\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-3/checkpoint-2274\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/output/run-3/checkpoint-1137 (score: 0.872485118481087).\n","\u001b[32m[I 2022-05-22 09:38:54,151]\u001b[0m Trial 3 finished with value: 3.5066623541536375 and parameters: {'learning_rate': 2.800556082463261e-05, 'num_train_epochs': 7}. Best is trial 3 with value: 3.5066623541536375.\u001b[0m\n","Trial:\n","loading configuration file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 48483\n","  Num Epochs = 9\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3411\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3411' max='3411' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3411/3411 1:22:50, Epoch 9/9]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.917200</td>\n","      <td>0.654390</td>\n","      <td>0.735675</td>\n","      <td>0.726049</td>\n","      <td>0.694632</td>\n","      <td>0.706198</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.588400</td>\n","      <td>0.550067</td>\n","      <td>0.782678</td>\n","      <td>0.782032</td>\n","      <td>0.740357</td>\n","      <td>0.755353</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.484000</td>\n","      <td>0.508161</td>\n","      <td>0.810404</td>\n","      <td>0.798473</td>\n","      <td>0.790166</td>\n","      <td>0.792282</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.431800</td>\n","      <td>0.472684</td>\n","      <td>0.828096</td>\n","      <td>0.815455</td>\n","      <td>0.807280</td>\n","      <td>0.811149</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.383300</td>\n","      <td>0.451392</td>\n","      <td>0.836810</td>\n","      <td>0.829920</td>\n","      <td>0.813672</td>\n","      <td>0.820563</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.357800</td>\n","      <td>0.434375</td>\n","      <td>0.844204</td>\n","      <td>0.834222</td>\n","      <td>0.822761</td>\n","      <td>0.827905</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.346000</td>\n","      <td>0.440273</td>\n","      <td>0.842355</td>\n","      <td>0.842344</td>\n","      <td>0.811722</td>\n","      <td>0.824409</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.333900</td>\n","      <td>0.435821</td>\n","      <td>0.846844</td>\n","      <td>0.846145</td>\n","      <td>0.814953</td>\n","      <td>0.827811</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.324300</td>\n","      <td>0.432722</td>\n","      <td>0.848957</td>\n","      <td>0.845218</td>\n","      <td>0.820322</td>\n","      <td>0.830969</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-4/checkpoint-379\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-4/checkpoint-758\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-4/checkpoint-1137\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-4/checkpoint-1516\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-4/checkpoint-1895\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-4/checkpoint-2274\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-4/checkpoint-2653\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-4/checkpoint-3032\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-4/checkpoint-3411\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/output/run-4/checkpoint-3411 (score: 0.8309693160014273).\n","\u001b[32m[I 2022-05-22 11:01:47,399]\u001b[0m Trial 4 finished with value: 3.345465727285132 and parameters: {'learning_rate': 5.152385754048399e-06, 'num_train_epochs': 9}. Best is trial 3 with value: 3.5066623541536375.\u001b[0m\n","Trial:\n","loading configuration file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 48483\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1895\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='379' max='1895' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 379/1895 09:06 < 36:38, 0.69 it/s, Epoch 1/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.883500</td>\n","      <td>0.614402</td>\n","      <td>0.756800</td>\n","      <td>0.750687</td>\n","      <td>0.715579</td>\n","      <td>0.728616</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","\u001b[32m[I 2022-05-22 11:10:57,201]\u001b[0m Trial 5 pruned. \u001b[0m\n","Trial:\n","loading configuration file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 48483\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2653\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2274' max='2653' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2274/2653 55:15 < 09:12, 0.69 it/s, Epoch 6/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.636700</td>\n","      <td>0.423374</td>\n","      <td>0.862688</td>\n","      <td>0.863897</td>\n","      <td>0.838258</td>\n","      <td>0.848940</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.319400</td>\n","      <td>0.315070</td>\n","      <td>0.890943</td>\n","      <td>0.888615</td>\n","      <td>0.872611</td>\n","      <td>0.879760</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.226800</td>\n","      <td>0.327628</td>\n","      <td>0.894111</td>\n","      <td>0.884217</td>\n","      <td>0.876431</td>\n","      <td>0.880145</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.169400</td>\n","      <td>0.352000</td>\n","      <td>0.891999</td>\n","      <td>0.889376</td>\n","      <td>0.869945</td>\n","      <td>0.878152</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.121700</td>\n","      <td>0.360983</td>\n","      <td>0.891207</td>\n","      <td>0.878972</td>\n","      <td>0.871034</td>\n","      <td>0.874769</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.092000</td>\n","      <td>0.397558</td>\n","      <td>0.887246</td>\n","      <td>0.861654</td>\n","      <td>0.872599</td>\n","      <td>0.866625</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-6/checkpoint-379\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-6/checkpoint-758\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-6/checkpoint-1137\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-6/checkpoint-1516\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-6/checkpoint-1895\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-6/checkpoint-2274\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/output/run-6/checkpoint-1137 (score: 0.8801449189660134).\n","\u001b[32m[I 2022-05-22 12:06:15,236]\u001b[0m Trial 6 finished with value: 3.4881236149729866 and parameters: {'learning_rate': 4.5815794772193134e-05, 'num_train_epochs': 7}. Best is trial 3 with value: 3.5066623541536375.\u001b[0m\n","Trial:\n","loading configuration file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 48483\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3790\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='379' max='3790' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 379/3790 09:06 < 1:22:23, 0.69 it/s, Epoch 1/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.867600</td>\n","      <td>0.593333</td>\n","      <td>0.762609</td>\n","      <td>0.762063</td>\n","      <td>0.722201</td>\n","      <td>0.736259</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","\u001b[32m[I 2022-05-22 12:15:25,311]\u001b[0m Trial 7 pruned. \u001b[0m\n","Trial:\n","loading configuration file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/NLP/Setiment_Analysis/en/save_pretrained/exp_2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 48483\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2653\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='449' max='2653' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 449/2653 10:46 < 53:08, 0.69 it/s, Epoch 1.18/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.708500</td>\n","      <td>0.434394</td>\n","      <td>0.842355</td>\n","      <td>0.838046</td>\n","      <td>0.818150</td>\n","      <td>0.826652</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 3787\n","  Batch size = 128\n","Saving model checkpoint to /content/output/run-8/checkpoint-379\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"K-6BlFBVizbn"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Roberta_MLM_SA_AUG_LSTM.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8bfe5f5455124ba293da489f372b364e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0a8d8e253204a9ca3b080dd58b56897","IPY_MODEL_eb10f905bc0a402c9009d248c65912a0","IPY_MODEL_55c50fda40384b40831a7e51aa09b9ef"],"layout":"IPY_MODEL_8d7da57c140e4263a05a9cbaa6a2f732"}},"f0a8d8e253204a9ca3b080dd58b56897":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53d85775b56e45b6bdf250ccd48b6b8b","placeholder":"​","style":"IPY_MODEL_1f41673a4800441ba0c1f962b823b77c","value":"Downloading: 100%"}},"eb10f905bc0a402c9009d248c65912a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83a8fa136d8e4f3394b071c115cea31b","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b9cf8e1fa3cf4952befd2412bd0a0481","value":898823}},"55c50fda40384b40831a7e51aa09b9ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_091bff1ac7c54eea9fc0aff38f13062d","placeholder":"​","style":"IPY_MODEL_e50b2a08f58d463593c401ba1a853446","value":" 878k/878k [00:01&lt;00:00, 1.14MB/s]"}},"8d7da57c140e4263a05a9cbaa6a2f732":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53d85775b56e45b6bdf250ccd48b6b8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f41673a4800441ba0c1f962b823b77c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83a8fa136d8e4f3394b071c115cea31b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9cf8e1fa3cf4952befd2412bd0a0481":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"091bff1ac7c54eea9fc0aff38f13062d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e50b2a08f58d463593c401ba1a853446":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f1d4849d52b4800be0f5a77573e0269":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9cb9e7708384d14ae670cb0fe7a9c43","IPY_MODEL_f0cec2da338445ec90bc9fbfb375d3b3","IPY_MODEL_4e60751145f84b0780f6c9efe045033b"],"layout":"IPY_MODEL_43263f467ae04bb8b0c14cd3a458a10f"}},"b9cb9e7708384d14ae670cb0fe7a9c43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b48c696108a24ed297a84641c21795fa","placeholder":"​","style":"IPY_MODEL_1c5dd3aaa9014c5d8f1ca4a0cb86df57","value":"Downloading: 100%"}},"f0cec2da338445ec90bc9fbfb375d3b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca42bad3ddf942cca6912ab2c00356d6","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c3795a5c65442b78dc00a612adef816","value":456318}},"4e60751145f84b0780f6c9efe045033b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_076f4544298046a188f0df2b53b80891","placeholder":"​","style":"IPY_MODEL_aef753d83eef48f0b73b210ba25c7c1c","value":" 446k/446k [00:00&lt;00:00, 701kB/s]"}},"43263f467ae04bb8b0c14cd3a458a10f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b48c696108a24ed297a84641c21795fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c5dd3aaa9014c5d8f1ca4a0cb86df57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca42bad3ddf942cca6912ab2c00356d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c3795a5c65442b78dc00a612adef816":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"076f4544298046a188f0df2b53b80891":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aef753d83eef48f0b73b210ba25c7c1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3c373fc256a4bf4b6dc8bb45ac9c5e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a43672ffcfd4ceaad8672f11e416d53","IPY_MODEL_3d079373fd9d48c294ba1cc24a94123e","IPY_MODEL_1230bcd2d0c7430a8930c1c8dc86ded6"],"layout":"IPY_MODEL_30765293fe4f4253840765e5988508dd"}},"7a43672ffcfd4ceaad8672f11e416d53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74b38ee6396a4479996201e0fbd26f91","placeholder":"​","style":"IPY_MODEL_650dc7db920c47cc84deeab5fc5813a5","value":"Downloading: 100%"}},"3d079373fd9d48c294ba1cc24a94123e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24e5773a3e314154942f963bf55ac0ad","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0a0b2f09de44e15b3b7ac4e731ddfe5","value":481}},"1230bcd2d0c7430a8930c1c8dc86ded6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bc5ef78a544484ca8e72727e84c914d","placeholder":"​","style":"IPY_MODEL_fe8c393bd7c240cfaecba0d0f54e417d","value":" 481/481 [00:00&lt;00:00, 11.2kB/s]"}},"30765293fe4f4253840765e5988508dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74b38ee6396a4479996201e0fbd26f91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"650dc7db920c47cc84deeab5fc5813a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24e5773a3e314154942f963bf55ac0ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0a0b2f09de44e15b3b7ac4e731ddfe5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7bc5ef78a544484ca8e72727e84c914d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe8c393bd7c240cfaecba0d0f54e417d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b8187b8be89420a8d9e915c781b6e01":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfd469b88ab744dcaec6c936ac67c628","IPY_MODEL_b8783f42996f4e3099f86e7ad3d1dff5","IPY_MODEL_f4d4ca3d6c4f48c9a17e68df5dafd400"],"layout":"IPY_MODEL_038c27c392fd462c9ac1cb17c143ea91"}},"dfd469b88ab744dcaec6c936ac67c628":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8616bdd6d8ab4a32a11f0b124cb669b1","placeholder":"​","style":"IPY_MODEL_3307bcecd950446d86f8971cc7f1b474","value":"Downloading data files: 100%"}},"b8783f42996f4e3099f86e7ad3d1dff5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_56413c54867445babffacd4fd9f86b30","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_792857cfc1504883adc806f4f564c6a5","value":2}},"f4d4ca3d6c4f48c9a17e68df5dafd400":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_032c823fe70e4bb697487258a231daee","placeholder":"​","style":"IPY_MODEL_ccfcd5cf8a1e47f09b2b1437887b78f4","value":" 2/2 [00:00&lt;00:00, 72.66it/s]"}},"038c27c392fd462c9ac1cb17c143ea91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8616bdd6d8ab4a32a11f0b124cb669b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3307bcecd950446d86f8971cc7f1b474":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56413c54867445babffacd4fd9f86b30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"792857cfc1504883adc806f4f564c6a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"032c823fe70e4bb697487258a231daee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccfcd5cf8a1e47f09b2b1437887b78f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5a1808efef940f68941689cbef8b61c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c80e5183e8d54c078771c12581680d4e","IPY_MODEL_cdb381a4eb774471bcfcffa6a27dba75","IPY_MODEL_2343bef247a64e52ad3c06824c79e4bd"],"layout":"IPY_MODEL_8e3097ec32cb48eeb62638dbe57f417a"}},"c80e5183e8d54c078771c12581680d4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59d6e59d39b742dfbbb9bdd98c5ee12c","placeholder":"​","style":"IPY_MODEL_da1d62701c354500acec104851a5e2da","value":"Extracting data files: 100%"}},"cdb381a4eb774471bcfcffa6a27dba75":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0741c9e622c84959a894cf92e376c335","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9f81ea69cf8464d9b8faf9af2521bf4","value":2}},"2343bef247a64e52ad3c06824c79e4bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf8f70c83b864c559348ce8b2b26ac11","placeholder":"​","style":"IPY_MODEL_6cdfed30cfbf4b799d6ea6c896c27820","value":" 2/2 [00:00&lt;00:00, 42.32it/s]"}},"8e3097ec32cb48eeb62638dbe57f417a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59d6e59d39b742dfbbb9bdd98c5ee12c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da1d62701c354500acec104851a5e2da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0741c9e622c84959a894cf92e376c335":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9f81ea69cf8464d9b8faf9af2521bf4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf8f70c83b864c559348ce8b2b26ac11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cdfed30cfbf4b799d6ea6c896c27820":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2b315c15c4e4c5ba3be7e45cb2e7aa3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45155038522c489aa442ad3ca6e4aece","IPY_MODEL_e164af8df49740d7bcb0c303f098eade","IPY_MODEL_96374ec1ad71469094e50029291c3778"],"layout":"IPY_MODEL_d0b70dc24991452ead8a0d6817fc6086"}},"45155038522c489aa442ad3ca6e4aece":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35c0352794624c9595fe5f5456067d78","placeholder":"​","style":"IPY_MODEL_54d0d38bdda4400291c19ebf97ca7545","value":"100%"}},"e164af8df49740d7bcb0c303f098eade":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9968c5be25e94cc7b70e1cde3e242063","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3167a4583c84a919eb2dacf5686bb68","value":2}},"96374ec1ad71469094e50029291c3778":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b42520602b04437b20a8ed7db6fb52c","placeholder":"​","style":"IPY_MODEL_12a3cdb608444a61a388417ad2ca0364","value":" 2/2 [00:00&lt;00:00, 74.15it/s]"}},"d0b70dc24991452ead8a0d6817fc6086":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35c0352794624c9595fe5f5456067d78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54d0d38bdda4400291c19ebf97ca7545":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9968c5be25e94cc7b70e1cde3e242063":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3167a4583c84a919eb2dacf5686bb68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b42520602b04437b20a8ed7db6fb52c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12a3cdb608444a61a388417ad2ca0364":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02af12f86808471b9150ad42cae9804b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_567ffa86e77547d1904e7f5beea53df5","IPY_MODEL_032e6139d41f4fe0b8148f06f044ee06","IPY_MODEL_88b61bde4c5e4bb48479e822c90874f2"],"layout":"IPY_MODEL_fd506beb6b394c9daa5be29de3de3af1"}},"567ffa86e77547d1904e7f5beea53df5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91d770ee6fcb4d388e5dfa0cec6cb774","placeholder":"​","style":"IPY_MODEL_1d830139b1f345aa8dd6aa4153e77279","value":"100%"}},"032e6139d41f4fe0b8148f06f044ee06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9dd0ce841af481d96ad1203bf0e93c4","max":48483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e82b0c38408d4335a0fca1b0dccec435","value":48483}},"88b61bde4c5e4bb48479e822c90874f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22706a62b9364d01bf7c764aca294ebf","placeholder":"​","style":"IPY_MODEL_ab76ae10b2bb41a59fb525d292aee98f","value":" 48483/48483 [00:02&lt;00:00, 16428.60ex/s]"}},"fd506beb6b394c9daa5be29de3de3af1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91d770ee6fcb4d388e5dfa0cec6cb774":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d830139b1f345aa8dd6aa4153e77279":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9dd0ce841af481d96ad1203bf0e93c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e82b0c38408d4335a0fca1b0dccec435":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"22706a62b9364d01bf7c764aca294ebf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab76ae10b2bb41a59fb525d292aee98f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd696601313a477ba2c93d19f6134f73":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9bc5856a783d40cb87b3a5839034aa9e","IPY_MODEL_2ce2e818d7444127b2996cd191edf34f","IPY_MODEL_ed9e498806ec46ebb74ee37f72d65ae8"],"layout":"IPY_MODEL_3ae845b1e2e1471cb89e5ad0463e1b55"}},"9bc5856a783d40cb87b3a5839034aa9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_709cf7a56f3348e894dd322c6fffb6c9","placeholder":"​","style":"IPY_MODEL_700addea38a34ce8b0ea5ce4af900067","value":"100%"}},"2ce2e818d7444127b2996cd191edf34f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fb68d70471b4d59893cc240f185004a","max":3787,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f58bc6605664f7bae3923479cabc1f2","value":3787}},"ed9e498806ec46ebb74ee37f72d65ae8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a7818805116496da60a86a5dd5a4bc0","placeholder":"​","style":"IPY_MODEL_fbc100ee3d58460dae843384000ce883","value":" 3787/3787 [00:00&lt;00:00, 15729.45ex/s]"}},"3ae845b1e2e1471cb89e5ad0463e1b55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"709cf7a56f3348e894dd322c6fffb6c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"700addea38a34ce8b0ea5ce4af900067":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fb68d70471b4d59893cc240f185004a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f58bc6605664f7bae3923479cabc1f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a7818805116496da60a86a5dd5a4bc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbc100ee3d58460dae843384000ce883":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"460e860ed15c44a59f7885c19f559f48":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a3891ada27584f85918d051dd8ca786b","IPY_MODEL_b257631d46e240fd972331a0edde4198","IPY_MODEL_5131595b56f64ce093f435aec7d24ec2"],"layout":"IPY_MODEL_16f8a3580d4947a1afe8a69abbba5363"}},"a3891ada27584f85918d051dd8ca786b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b01130a2d73f47d6addead9be14f7925","placeholder":"​","style":"IPY_MODEL_44417b36175a40cebf178be2b203c5dd","value":"100%"}},"b257631d46e240fd972331a0edde4198":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd4d01df02884d21a89a7d4d5da2e808","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ebcbd7b7a3f4b778b052dc786ed3fe7","value":49}},"5131595b56f64ce093f435aec7d24ec2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9841ed5236634365a0060270aa7235d2","placeholder":"​","style":"IPY_MODEL_032a30131aaf458fa162b1fc3130f2a2","value":" 49/49 [00:16&lt;00:00,  3.64ba/s]"}},"16f8a3580d4947a1afe8a69abbba5363":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b01130a2d73f47d6addead9be14f7925":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44417b36175a40cebf178be2b203c5dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd4d01df02884d21a89a7d4d5da2e808":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ebcbd7b7a3f4b778b052dc786ed3fe7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9841ed5236634365a0060270aa7235d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"032a30131aaf458fa162b1fc3130f2a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a14b6787f819406f9408463345b00624":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2fbaf0d41a7a40788aebe81a3096cf6b","IPY_MODEL_9aea277dc0b248648a3f5e04237af5a8","IPY_MODEL_afe6844a6cdc46eca0041e5908cb358e"],"layout":"IPY_MODEL_0ac7ae015fb2420792aac2c507ead171"}},"2fbaf0d41a7a40788aebe81a3096cf6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c2de58f3add41e0a6a9c721c60f9176","placeholder":"​","style":"IPY_MODEL_04af3918820743b5981b27c3d53dd29b","value":"100%"}},"9aea277dc0b248648a3f5e04237af5a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_350ac5c5238243ae967238256cffa842","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4dfe1f11fc5b4b5abace25a0252b0a6e","value":4}},"afe6844a6cdc46eca0041e5908cb358e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7176825f0984128babae6d5f93787ca","placeholder":"​","style":"IPY_MODEL_f0bbef3c525a4486bdd8ca0dc24f8eef","value":" 4/4 [00:01&lt;00:00,  2.77ba/s]"}},"0ac7ae015fb2420792aac2c507ead171":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c2de58f3add41e0a6a9c721c60f9176":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04af3918820743b5981b27c3d53dd29b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"350ac5c5238243ae967238256cffa842":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dfe1f11fc5b4b5abace25a0252b0a6e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7176825f0984128babae6d5f93787ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0bbef3c525a4486bdd8ca0dc24f8eef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6988625fa4143bcb7ffc326d114b400":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e38893acdca74adb9428c6bca00a55cd","IPY_MODEL_c5259c1e1e644788918a6aabc21e91cc","IPY_MODEL_208ea26534f94cecaf23e1d46d95c9ed"],"layout":"IPY_MODEL_ac63c51c73fc4489a13e06414684a7b2"}},"e38893acdca74adb9428c6bca00a55cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eccd79dae01a45fb8043fd2731e6ce6b","placeholder":"​","style":"IPY_MODEL_b85bd6fd102944559b8ed97b97e41d51","value":"Downloading builder script: "}},"c5259c1e1e644788918a6aabc21e91cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a421740aaa254becb4ecc79b9e5a2722","max":1652,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ebab5378de424e07a18e755b78734c51","value":1652}},"208ea26534f94cecaf23e1d46d95c9ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f9973f4d878444c89feb54bed3c3b64","placeholder":"​","style":"IPY_MODEL_1ac507570a5043a1afe82d3b25bbf440","value":" 4.21k/? [00:00&lt;00:00, 168kB/s]"}},"ac63c51c73fc4489a13e06414684a7b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eccd79dae01a45fb8043fd2731e6ce6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b85bd6fd102944559b8ed97b97e41d51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a421740aaa254becb4ecc79b9e5a2722":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebab5378de424e07a18e755b78734c51":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f9973f4d878444c89feb54bed3c3b64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ac507570a5043a1afe82d3b25bbf440":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bb17205d3964fcebdeb4bb07d764b1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40fe2d6577474dc0abfb953ccf65d313","IPY_MODEL_8a6164522f1b4864b5b4c0130b8852f2","IPY_MODEL_3075d2e71e6b4152810c6a9504a5b24b"],"layout":"IPY_MODEL_e2ab839c40d0485682eaa2d65d7cb979"}},"40fe2d6577474dc0abfb953ccf65d313":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70148f1330f9473487dab281dec80fdb","placeholder":"​","style":"IPY_MODEL_f1ad950d3f92453088a033e8509e2d72","value":"Downloading builder script: "}},"8a6164522f1b4864b5b4c0130b8852f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fc408e5f2e141f69c8ae835f85ed9a7","max":2575,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b43ad3ca67b43afa0a7f0d27477464e","value":2575}},"3075d2e71e6b4152810c6a9504a5b24b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5afd6f197e4142e3bb8dd2102601fd5b","placeholder":"​","style":"IPY_MODEL_4de7ff5eca884345b45eb1f86b45958e","value":" 7.55k/? [00:00&lt;00:00, 302kB/s]"}},"e2ab839c40d0485682eaa2d65d7cb979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70148f1330f9473487dab281dec80fdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1ad950d3f92453088a033e8509e2d72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fc408e5f2e141f69c8ae835f85ed9a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b43ad3ca67b43afa0a7f0d27477464e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5afd6f197e4142e3bb8dd2102601fd5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4de7ff5eca884345b45eb1f86b45958e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f2f2b1790ec4c609a343ddd86bba245":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8771f51d5ee94b729e2dda3cf60580cf","IPY_MODEL_644ad60936754a67849329a6533061b1","IPY_MODEL_498d852f11404519b6b5b31311aec4ad"],"layout":"IPY_MODEL_04ccffbdfbab4b04b9f6c6ef3e17434d"}},"8771f51d5ee94b729e2dda3cf60580cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_037ef7b1af3c47a69e157ffe0da9b3ea","placeholder":"​","style":"IPY_MODEL_105187ade65e4861b9243895edbfd83b","value":"Downloading builder script: "}},"644ad60936754a67849329a6533061b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_048ab5db3e384afc9474477b6a02e87e","max":2524,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48fd4ba86ade4b228234626d09982f81","value":2524}},"498d852f11404519b6b5b31311aec4ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_696eb6f08be947e2a5d90966d0ccff64","placeholder":"​","style":"IPY_MODEL_a4f54c3c5d3f42bda034899d93eaa1f1","value":" 7.38k/? [00:00&lt;00:00, 314kB/s]"}},"04ccffbdfbab4b04b9f6c6ef3e17434d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"037ef7b1af3c47a69e157ffe0da9b3ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"105187ade65e4861b9243895edbfd83b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"048ab5db3e384afc9474477b6a02e87e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48fd4ba86ade4b228234626d09982f81":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"696eb6f08be947e2a5d90966d0ccff64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4f54c3c5d3f42bda034899d93eaa1f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be5202ce3f1a47a1a493f52a07460993":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de702a633b8145108310729419fbdde4","IPY_MODEL_5a0f67bb19b0407da0d87a45472570a9","IPY_MODEL_7ece19f024074212a6427c78ea1c848c"],"layout":"IPY_MODEL_d63e171c687246f49a1e02e1fa8e66b2"}},"de702a633b8145108310729419fbdde4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51e1959c5fd54734beca7252179a4779","placeholder":"​","style":"IPY_MODEL_ed71bb5f209d4115a5cfb3f93e293385","value":"Downloading builder script: "}},"5a0f67bb19b0407da0d87a45472570a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7aa6737babde43da8232287f9ce04b2f","max":2318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a73a1fd33f341e9854b4d352cb65ca3","value":2318}},"7ece19f024074212a6427c78ea1c848c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0406f433f14946459d9633041c0aa4c8","placeholder":"​","style":"IPY_MODEL_69401b008f0f425db66ae7a75e118808","value":" 6.50k/? [00:00&lt;00:00, 281kB/s]"}},"d63e171c687246f49a1e02e1fa8e66b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51e1959c5fd54734beca7252179a4779":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed71bb5f209d4115a5cfb3f93e293385":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7aa6737babde43da8232287f9ce04b2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a73a1fd33f341e9854b4d352cb65ca3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0406f433f14946459d9633041c0aa4c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69401b008f0f425db66ae7a75e118808":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}